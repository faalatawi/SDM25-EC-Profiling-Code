{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.stats import kendalltau\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def U_normalize(Adj):\n",
    "    return normalize(Adj, norm='l1', axis=1)\n",
    "\n",
    "def V_normalize(Adj):\n",
    "    return normalize(Adj, norm='l1', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is gun\n"
     ]
    }
   ],
   "source": [
    "dataset = ['abortion','gun'][1]\n",
    "\n",
    "print(f\"The dataset is {dataset}\")\n",
    "\n",
    "df_words_list = pd.read_parquet(f'output/{dataset}/list_of_words.parquet')\n",
    "df_topics = pd.read_parquet(f'output/{dataset}/topics.parquet')\n",
    "df_tweets = pd.read_parquet(f'output/{dataset}/tweets.parquet')\n",
    "df_users = pd.read_parquet(f'output/{dataset}/uid_to_index.parquet')\n",
    "df_label = pd.read_feather(f'data/{dataset}/allsides.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((117327, 4404), (117327, 8818), (117327, 61))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TW2U = sp.load_npz(f'output/{dataset}/Tweets2Users_sparse.npz')\n",
    "TW2W = sp.load_npz(f'output/{dataset}/X_Tweets_sparse.npz')\n",
    "TW2T = sp.load_npz(f'output/{dataset}/Tweets2Topics_sparse.npz')\n",
    "\n",
    "TW2U.shape, TW2W.shape, TW2T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4404,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Users_Labels = np.load(f'output/{dataset}/users_labels_(Same_word_as_Tweets2Users).npy')\n",
    "Users_Labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Users_Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Num of 0s: 2237, Num of 1s: 2167'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the 0s and the 1s\n",
    "f\"Num of 0s: {np.sum(Users_Labels == 0)}, Num of 1s: {np.sum(Users_Labels == 1)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4404,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ids = df_users['user_id'].values\n",
    "user_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4404"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uid2label = dict(zip(user_ids, Users_Labels))\n",
    "len(uid2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    60699\n",
       "1    56628\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets['label'] = df_tweets['user_id'].map(uid2label)\n",
    "df_tweets['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117327,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_label = df_tweets['label'].values\n",
    "tweet_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_list = df_words_list['word'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_tweets(topic: str, label: str, keyword: str, num = 10) -> list[str]:\n",
    "    \"\"\"\n",
    "    Returns a list of 10 tweets that match the specified topic, label, and keyword.\n",
    "    \n",
    "    Args:\n",
    "        topic (str): The topic of the tweets.\n",
    "        label (str): The label of the tweets.\n",
    "        keyword (str): The keyword to search for in the tweets.\n",
    "\n",
    "    Returns:\n",
    "        list[str]: A list of 10 tweet IDs that match the specified criteria.\n",
    "    \"\"\"\n",
    "\n",
    "    # Filter the tweets by topic and label\n",
    "    filtered_tweets = df_tweets.query(f\"topic == @topic and label == @label\")\n",
    "    \n",
    "    # Filter the remaining tweets to contain the keyword (case-insensitive)\n",
    "    matching_tweets = filtered_tweets[df_tweets.tweet.str.contains(keyword, case=False)]\n",
    "    \n",
    "    # print(matching_tweets.shape)\n",
    "    \n",
    "    if matching_tweets.shape[0] < num:\n",
    "        return matching_tweets\n",
    "    else:\n",
    "        return matching_tweets.sample(num)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keywords of Community:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "T2TW = TW2T.T\n",
    "\n",
    "\n",
    "# T -> TW -> W\n",
    "T2TW_0 = T2TW[:, tweet_label == 0]\n",
    "TW2W_0 = TW2W[tweet_label == 0, :]\n",
    "# T2TW_0.shape, TW2W_0.shape\n",
    "PM_L = U_normalize(T2TW_0)\n",
    "PM_R = V_normalize(TW2W_0)\n",
    "\n",
    "HS_T2W_C0 = cosine_similarity(PM_L, PM_R.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "T2TW_1 = T2TW[:, tweet_label == 1]\n",
    "TW2W_1 = TW2W[tweet_label == 1, :]\n",
    "PM_L = U_normalize(T2TW_1)\n",
    "PM_R = V_normalize(TW2W_1)\n",
    "\n",
    "HS_T2W_C1 = cosine_similarity(PM_L, PM_R.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All \n",
    "PM_L = U_normalize(T2TW)\n",
    "PM_R = V_normalize(TW2W)\n",
    "\n",
    "HS_T2W_ALL = cosine_similarity(PM_L, PM_R.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_words(topic_id, print_out = False) -> tuple:\n",
    "    topic_name = df_topics['Name'][topic_id]\n",
    "    \n",
    "    # The topic words\n",
    "    all_words_ids = np.argsort(HS_T2W_ALL[topic_id])[::-1][:10]\n",
    "    topic_words = words_list[all_words_ids][:10]\n",
    "    \n",
    "    # The profile words\n",
    "    score_c0_topic = HS_T2W_C0[topic_id] - HS_T2W_C1[topic_id]\n",
    "    c0_words = words_list[np.argsort(score_c0_topic)[::-1][:10]]\n",
    "    c0_scores = np.sort(score_c0_topic)[::-1][:10]\n",
    "    \n",
    "    score_c1_topic = HS_T2W_C1[topic_id] - HS_T2W_C0[topic_id]\n",
    "    c1_words = words_list[np.argsort(score_c1_topic)[::-1][:10]]\n",
    "    c1_scores = np.sort(score_c1_topic)[::-1][:10]\n",
    "    \n",
    "    if print_out:\n",
    "        print(f\"Topic name: {topic_name}\")\n",
    "        \n",
    "        print(f\"\\t Topic Words: {topic_words}\")\n",
    "        print(f\"\\t C0 Words: {c0_words}\")\n",
    "        print(f\"\\t C0 Scores: {c0_scores}\")\n",
    "        print(f\"\\t C1 Words: {c1_words}\")\n",
    "        print(f\"\\t C1 Scores: {c1_scores}\")\n",
    "\n",
    "    return topic_name, topic_words, (c0_words, c0_scores), (c1_words, c1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic name: 1_fbi_trump_doj_court\n",
      "\t Topic Words: ['fbi' 'trump' 'doj' 'documents' 'court' 'garland' 'justice' 'mar'\n",
      " 'classified' 'lago']\n",
      "\t C0 Words: ['trump' 'classified' 'documents' 'donald' 'thomas' 'secret' 'indict'\n",
      " 'espionage' 'garland' 'lawyers']\n",
      "\t C0 Scores: [0.17126463 0.13147257 0.12955069 0.09710182 0.09000833 0.08846839\n",
      " 0.08845118 0.08465685 0.08097294 0.07947844]\n",
      "\t C1 Words: ['fbi' 'raid' 'dossier' 'whistleblowers' 'collusion' 'hoax' 'prisoners'\n",
      " 'hillary' 'political' 'spying']\n",
      "\t C1 Scores: [0.19060109 0.13710187 0.07292381 0.07126841 0.07099452 0.06496717\n",
      " 0.06293037 0.05838423 0.05324517 0.04604267]\n"
     ]
    }
   ],
   "source": [
    "_ = get_topic_words(1, print_out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7585/1363276776.py:18: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  matching_tweets = filtered_tweets[df_tweets.tweet.str.contains(keyword, case=False)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>topic</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>50401467</td>\n",
       "      <td>“Not a shadow of a doubt,” said his attorney, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7344</th>\n",
       "      <td>27386099</td>\n",
       "      <td>Clarence Thomas, Lindsey Graham, shadow docket...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41298</th>\n",
       "      <td>1294339508687654914</td>\n",
       "      <td>New Trump special counsel launches investigati...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65421</th>\n",
       "      <td>1122907600465608706</td>\n",
       "      <td>Trump is running a shadow presidency, threaten...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80421</th>\n",
       "      <td>48508105</td>\n",
       "      <td>\"Shadow docket use by the - conservative major...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88595</th>\n",
       "      <td>1345821572255379458</td>\n",
       "      <td>GLENS FALLS, N.Y. — Matt Castelli has spent mu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   user_id                                              tweet  \\\n",
       "1828              50401467  “Not a shadow of a doubt,” said his attorney, ...   \n",
       "7344              27386099  Clarence Thomas, Lindsey Graham, shadow docket...   \n",
       "41298  1294339508687654914  New Trump special counsel launches investigati...   \n",
       "65421  1122907600465608706  Trump is running a shadow presidency, threaten...   \n",
       "80421             48508105  \"Shadow docket use by the - conservative major...   \n",
       "88595  1345821572255379458  GLENS FALLS, N.Y. — Matt Castelli has spent mu...   \n",
       "\n",
       "       topic  label  \n",
       "1828       1      0  \n",
       "7344       1      0  \n",
       "41298      1      0  \n",
       "65421      1      0  \n",
       "80421      1      0  \n",
       "88595      1      0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp = sample_tweets(1, 0, \"shadow\", 10)\n",
    "df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['“Not a shadow of a doubt,” said his attorney, probably',\n",
       "       'Clarence Thomas, Lindsey Graham, shadow docket… yeah this turned out as expected.',\n",
       "       'New Trump special counsel launches investigation in Mueller’s shadow The Justice Department hopes to avoid pitfalls of the last special counsel investigation targeting Trump.',\n",
       "       'Trump is running a shadow presidency, threatening the Biden administration with disruptive protests like the Canadian trucking disruption. He needs to be charged with crimes against the United States immediately.',\n",
       "       '\"Shadow docket use by the - conservative majority court also became a political foil with Senate Democrats calling it a potential abuse.\" \"...Approximately % of those emergency docket orders were unanimous, with no justice noting their dissent.\"',\n",
       "       'GLENS FALLS, N.Y. — Matt Castelli has spent much of his career in the shadows. Over nearly  years at the CIA, he hunted down terrorists in one way or another...'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp.tweet.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>topic</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>1328055791769837569</td>\n",
       "      <td>One thing is clear: We must #ArrestTrump</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1328055791769837569</td>\n",
       "      <td>If we elect more Democratic Senators, we have ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>1328055791769837569</td>\n",
       "      <td>NEWS: Former Trump Chief of Staff Mark Meadows...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1328055791769837569</td>\n",
       "      <td>President Biden s SCOTUS nominee, Judge Ketanj...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1328055791769837569</td>\n",
       "      <td>Who else agrees that Clarence Thomas is compro...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117311</th>\n",
       "      <td>1397638838</td>\n",
       "      <td>Did Garland ever have any intention to prosecu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117313</th>\n",
       "      <td>1397638838</td>\n",
       "      <td>Unless Garland never had any intention to pros...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117314</th>\n",
       "      <td>1397638838</td>\n",
       "      <td>Biden MUST replace Garland since his letter to...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117316</th>\n",
       "      <td>1397638838</td>\n",
       "      <td>Biden MUST replace Garland since his letter to...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117318</th>\n",
       "      <td>1397638838</td>\n",
       "      <td>Biden MUST replace Garland since his letter to...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5971 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    user_id  \\\n",
       "114     1328055791769837569   \n",
       "133     1328055791769837569   \n",
       "134     1328055791769837569   \n",
       "141     1328055791769837569   \n",
       "145     1328055791769837569   \n",
       "...                     ...   \n",
       "117311           1397638838   \n",
       "117313           1397638838   \n",
       "117314           1397638838   \n",
       "117316           1397638838   \n",
       "117318           1397638838   \n",
       "\n",
       "                                                    tweet  topic  label  \n",
       "114              One thing is clear: We must #ArrestTrump      1      0  \n",
       "133     If we elect more Democratic Senators, we have ...      1      0  \n",
       "134     NEWS: Former Trump Chief of Staff Mark Meadows...      1      0  \n",
       "141     President Biden s SCOTUS nominee, Judge Ketanj...      1      0  \n",
       "145     Who else agrees that Clarence Thomas is compro...      1      0  \n",
       "...                                                   ...    ...    ...  \n",
       "117311  Did Garland ever have any intention to prosecu...      1      0  \n",
       "117313  Unless Garland never had any intention to pros...      1      0  \n",
       "117314  Biden MUST replace Garland since his letter to...      1      0  \n",
       "117316  Biden MUST replace Garland since his letter to...      1      0  \n",
       "117318  Biden MUST replace Garland since his letter to...      1      0  \n",
       "\n",
       "[5971 rows x 4 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfy = df_tweets.query(f\"topic == {1} and label == {0}\")\n",
    "dfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4404, 8818)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get a User to Word matrix we need to multiply the User to Tweet matrix with the Tweet to Word matrix\n",
    "U2TW = TW2U.T\n",
    "U2W = U2TW @ TW2W\n",
    "U2W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert U2W to binary matrix: 0 if the user does not use the word, 1 if the user uses the word\n",
    "U2W_bin = U2W.copy()\n",
    "U2W_bin[U2W_bin > 0] = 1\n",
    "U2W_bin[0].toarray()[U2W_bin[0].toarray() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2237, 8818), (2167, 8818))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U2W_bin_0 = U2W_bin[Users_Labels == 0]\n",
    "U2W_bin_1 = U2W_bin[Users_Labels == 1]\n",
    "U2W_bin_0.shape, U2W_bin_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 8818), (1, 8818))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the ratio of users that use the word\n",
    "ratio_0 = U2W_bin_0.sum(axis=0) / U2W_bin_0.shape[0]\n",
    "ratio_1 = U2W_bin_1.sum(axis=0) / U2W_bin_1.shape[0]\n",
    "ratio_0.shape, ratio_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8818,), (8818,))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten the ratio arrays\n",
    "ratio_0 = ratio_0.A1\n",
    "ratio_1 = ratio_1.A1\n",
    "ratio_0.shape, ratio_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00849352, 0.00268216, 0.00625838, ..., 0.00402325, 0.00312919,\n",
       "       0.00581135])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>topic</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19937569</td>\n",
       "      <td>See. Proof. That conservatives are colluding w...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19937569</td>\n",
       "      <td>What say about release of #DoctorOfDeath #DrOf...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19937569</td>\n",
       "      <td>ALERT! Senator @SenGillibrand calls on DOJ and...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19937569</td>\n",
       "      <td>EVERY Gun Control Law INFRINGES upon the Const...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19937569</td>\n",
       "      <td>Nicholas Sandmann asks @elonmusk to release hi...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117322</th>\n",
       "      <td>881967184636895238</td>\n",
       "      <td>The opposite of prolife is deathcon</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117323</th>\n",
       "      <td>881967184636895238</td>\n",
       "      <td>Twitter be like \"oh you re viewing this profil...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117324</th>\n",
       "      <td>881967184636895238</td>\n",
       "      <td>They start with \"dress code\" and escalate to \"...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117325</th>\n",
       "      <td>881967184636895238</td>\n",
       "      <td>All this bitcoin farming generating runway mel...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117326</th>\n",
       "      <td>881967184636895238</td>\n",
       "      <td>My soul smells like cheap bourbon and piss</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117327 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   user_id                                              tweet  \\\n",
       "0                 19937569  See. Proof. That conservatives are colluding w...   \n",
       "1                 19937569  What say about release of #DoctorOfDeath #DrOf...   \n",
       "2                 19937569  ALERT! Senator @SenGillibrand calls on DOJ and...   \n",
       "3                 19937569  EVERY Gun Control Law INFRINGES upon the Const...   \n",
       "4                 19937569  Nicholas Sandmann asks @elonmusk to release hi...   \n",
       "...                    ...                                                ...   \n",
       "117322  881967184636895238                The opposite of prolife is deathcon   \n",
       "117323  881967184636895238  Twitter be like \"oh you re viewing this profil...   \n",
       "117324  881967184636895238  They start with \"dress code\" and escalate to \"...   \n",
       "117325  881967184636895238  All this bitcoin farming generating runway mel...   \n",
       "117326  881967184636895238         My soul smells like cheap bourbon and piss   \n",
       "\n",
       "        topic  label  \n",
       "0           2      1  \n",
       "1           2      1  \n",
       "2           2      1  \n",
       "3           2      1  \n",
       "4           0      1  \n",
       "...       ...    ...  \n",
       "117322     10      0  \n",
       "117323      0      0  \n",
       "117324     15      0  \n",
       "117325     36      0  \n",
       "117326     25      0  \n",
       "\n",
       "[117327 rows x 4 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_topic = df_tweets['topic'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_words_with_ratio(topic_id, print_out = False, limit = 10) -> tuple:\n",
    "    \n",
    "    # Compute the ratio of users that use the word\n",
    "    U2TW = TW2U.T\n",
    "    \n",
    "    \n",
    "    # keep the tweets about the topic\n",
    "    U2TW_t = U2TW[:, tweet_topic == topic_id]\n",
    "    TW2W_t = TW2W[tweet_topic == topic_id, :]\n",
    "    \n",
    "    U2W_t = U2TW_t @ TW2W_t\n",
    "    \n",
    "    U2W_bin_t = U2W_t.copy()\n",
    "    U2W_bin_t[U2W_bin_t > 0] = 1\n",
    "    \n",
    "    U2W_bin_0_t = U2W_bin_t[Users_Labels == 0, :]\n",
    "    U2W_bin_1_t = U2W_bin_t[Users_Labels == 1, :]\n",
    "    \n",
    "    ratio_0 = U2W_bin_0_t.sum(axis=0) / U2W_bin_0_t.shape[0]\n",
    "    ratio_1 = U2W_bin_1_t.sum(axis=0) / U2W_bin_1_t.shape[0]\n",
    "    \n",
    "    ratio_0 = ratio_0.A1\n",
    "    ratio_1 = ratio_1.A1\n",
    "    \n",
    "    \n",
    "    topic_name = df_topics['Name'][topic_id]\n",
    "    \n",
    "    # The topic words\n",
    "    all_words_ids = np.argsort(HS_T2W_ALL[topic_id])[::-1][:limit]\n",
    "    topic_words = words_list[all_words_ids][:limit]\n",
    "    \n",
    "    # The profile words\n",
    "    score_c0_topic = (HS_T2W_C0[topic_id] - HS_T2W_C1[topic_id]) * ratio_0\n",
    "    c0_words = words_list[np.argsort(score_c0_topic)[::-1][:limit]]\n",
    "    c0_scores = np.sort(score_c0_topic)[::-1][:limit]\n",
    "    \n",
    "    score_c1_topic = (HS_T2W_C1[topic_id] - HS_T2W_C0[topic_id]) * ratio_1\n",
    "    c1_words = words_list[np.argsort(score_c1_topic)[::-1][:limit]]\n",
    "    c1_scores = np.sort(score_c1_topic)[::-1][:limit]\n",
    "    \n",
    "    if print_out:\n",
    "        print(f\"Topic name: {topic_name}\")\n",
    "        \n",
    "        print(f\"\\t Topic Words: {topic_words}\")\n",
    "        print(f\"\\t C0 Words: {c0_words}\")\n",
    "        print(f\"\\t C0 Scores: {c0_scores}\")\n",
    "        print(f\"\\t C1 Words: {c1_words}\")\n",
    "        print(f\"\\t C1 Scores: {c1_scores}\")\n",
    "\n",
    "    return topic_name, topic_words, (c0_words, c0_scores), (c1_words, c1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic name: 13_border_illegal_migrants_southern\n",
      "\t Topic Words: ['border' 'migrants' 'illegal' 'immigration' 'southern' 'illegals'\n",
      " 'immigrants' 'fentanyl' 'patrol' 'mexico']\n",
      "\t C0 Words: ['immigration' 'migrants' 'mexico' 'migrant' 'immigrant' 'desantis'\n",
      " 'reform' 'administration' 'stunt' 'seeking']\n",
      "\t C0 Scores: [0.00140815 0.00136187 0.00132275 0.00108773 0.00034341 0.00023977\n",
      " 0.00023498 0.00022784 0.00017868 0.00015617]\n",
      "\t C1 Words: ['border' 'illegal' 'illegals' 'biden' 'amnesty' 'aliens' 'open'\n",
      " 'invasion' 'southern' 'borders']\n",
      "\t C1 Scores: [0.02059171 0.01854172 0.00935637 0.00734464 0.00705632 0.00634225\n",
      " 0.00483362 0.0043232  0.00411758 0.00355266]\n"
     ]
    }
   ],
   "source": [
    "_ = get_topic_words_with_ratio(13, print_out=True, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, World'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def join_and_Capitalize(str_list : list[str]) -> str:\n",
    "    # Join after cpitalizing the first letter of each word\n",
    "    return ', '.join([word.capitalize() for word in str_list])\n",
    "\n",
    "join_and_Capitalize(['hello', 'world'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>topic_words</th>\n",
       "      <th>c0_words</th>\n",
       "      <th>c1_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_twitter_musk_elon_elonmusk</td>\n",
       "      <td>Twitter, Elon, Musk, Elonmusk, Tweet, Tweets, ...</td>\n",
       "      <td>Musk, Elon, Twitter, New, Follow, Platform, Site</td>\n",
       "      <td>Elonmusk, Speech, Free, Censorship, Files, Cen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_fbi_trump_doj_court</td>\n",
       "      <td>Fbi, Trump, Doj, Documents, Court, Garland, Ju...</td>\n",
       "      <td>Trump, Documents, Court, Classified, Donald, G...</td>\n",
       "      <td>Fbi, Raid, Political, Collusion, Hillary, Hoax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2_gun_guns_police_shooting</td>\n",
       "      <td>Gun, Police, Guns, Shooting, Shot, Assault, We...</td>\n",
       "      <td>Shooting, Violence, Police, School, Mass, Kill...</td>\n",
       "      <td>Control, Gun, Owners, Rights, Carry, Ban, Fire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3_vote_election_republicans_gop</td>\n",
       "      <td>Vote, Election, Gop, Republicans, Democrats, P...</td>\n",
       "      <td>Democracy, Republicans, Gop, Vote, Blue, Repub...</td>\n",
       "      <td>Democrats, Election, Democrat, Ballots, Electi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4_stupid_know_yes_don</td>\n",
       "      <td>Stupid, Know, Lie, Yes, Don, Liar, True</td>\n",
       "      <td>Let, Hope, Right, Just, Mean, Need, Fucking</td>\n",
       "      <td>Don, Think, People, Lie, Lies, Truth, Know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56_security_social_medicare_seniors</td>\n",
       "      <td>Security, Social, Medicare, Seniors, Ss, Benef...</td>\n",
       "      <td>Security, Social, Medicare, Republicans, Gop, ...</td>\n",
       "      <td>Ss, Recipients, Income, Elimination, Increase,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57_mask_masks_wearing_wear</td>\n",
       "      <td>Mask, Masks, Wear, Wearing, Masking, Mandate, ...</td>\n",
       "      <td>Wear, Masks, Covid, Mask, Mandate, Flu, Wearing</td>\n",
       "      <td>Masking, Work, Masked, La, Driving, Science, H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>58_today_moment_currently_feel</td>\n",
       "      <td>Moment, Moon, Leo, Today, Currently, Spiritual...</td>\n",
       "      <td>Leo, Currently, Universe, Feel, Usual, Yo, Ach...</td>\n",
       "      <td>Prospect, Peer, Rude, Appearance, Recognition,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59_left_right_leftists_leftist</td>\n",
       "      <td>Left, Leftists, Leftist, Right, Wing, Radical,...</td>\n",
       "      <td>Right, Wing, Close, Far, Sides, Trying, Reacti...</td>\n",
       "      <td>Left, Leftists, Leftist, Hate, Destroy, Contro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60_tiktok_video_check_tik</td>\n",
       "      <td>Tiktok, Check, Video, Tik, Libs, User, Chinese</td>\n",
       "      <td>Video, Check, Content, Viral, Dance, Famous, L...</td>\n",
       "      <td>Tiktok, Ban, Chinese, China, Banning, Fcc, Com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  topic  \\\n",
       "0          0_twitter_musk_elon_elonmusk   \n",
       "1                 1_fbi_trump_doj_court   \n",
       "2            2_gun_guns_police_shooting   \n",
       "3       3_vote_election_republicans_gop   \n",
       "4                 4_stupid_know_yes_don   \n",
       "..                                  ...   \n",
       "56  56_security_social_medicare_seniors   \n",
       "57           57_mask_masks_wearing_wear   \n",
       "58       58_today_moment_currently_feel   \n",
       "59       59_left_right_leftists_leftist   \n",
       "60            60_tiktok_video_check_tik   \n",
       "\n",
       "                                          topic_words  \\\n",
       "0   Twitter, Elon, Musk, Elonmusk, Tweet, Tweets, ...   \n",
       "1   Fbi, Trump, Doj, Documents, Court, Garland, Ju...   \n",
       "2   Gun, Police, Guns, Shooting, Shot, Assault, We...   \n",
       "3   Vote, Election, Gop, Republicans, Democrats, P...   \n",
       "4             Stupid, Know, Lie, Yes, Don, Liar, True   \n",
       "..                                                ...   \n",
       "56  Security, Social, Medicare, Seniors, Ss, Benef...   \n",
       "57  Mask, Masks, Wear, Wearing, Masking, Mandate, ...   \n",
       "58  Moment, Moon, Leo, Today, Currently, Spiritual...   \n",
       "59  Left, Leftists, Leftist, Right, Wing, Radical,...   \n",
       "60     Tiktok, Check, Video, Tik, Libs, User, Chinese   \n",
       "\n",
       "                                             c0_words  \\\n",
       "0    Musk, Elon, Twitter, New, Follow, Platform, Site   \n",
       "1   Trump, Documents, Court, Classified, Donald, G...   \n",
       "2   Shooting, Violence, Police, School, Mass, Kill...   \n",
       "3   Democracy, Republicans, Gop, Vote, Blue, Repub...   \n",
       "4         Let, Hope, Right, Just, Mean, Need, Fucking   \n",
       "..                                                ...   \n",
       "56  Security, Social, Medicare, Republicans, Gop, ...   \n",
       "57    Wear, Masks, Covid, Mask, Mandate, Flu, Wearing   \n",
       "58  Leo, Currently, Universe, Feel, Usual, Yo, Ach...   \n",
       "59  Right, Wing, Close, Far, Sides, Trying, Reacti...   \n",
       "60  Video, Check, Content, Viral, Dance, Famous, L...   \n",
       "\n",
       "                                             c1_words  \n",
       "0   Elonmusk, Speech, Free, Censorship, Files, Cen...  \n",
       "1   Fbi, Raid, Political, Collusion, Hillary, Hoax...  \n",
       "2   Control, Gun, Owners, Rights, Carry, Ban, Fire...  \n",
       "3   Democrats, Election, Democrat, Ballots, Electi...  \n",
       "4          Don, Think, People, Lie, Lies, Truth, Know  \n",
       "..                                                ...  \n",
       "56  Ss, Recipients, Income, Elimination, Increase,...  \n",
       "57  Masking, Work, Masked, La, Driving, Science, H...  \n",
       "58  Prospect, Peer, Rude, Appearance, Recognition,...  \n",
       "59  Left, Leftists, Leftist, Hate, Destroy, Contro...  \n",
       "60  Tiktok, Ban, Chinese, China, Banning, Fcc, Com...  \n",
       "\n",
       "[61 rows x 4 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "records = []\n",
    "\n",
    "for t in range(len(df_topics)):\n",
    "    topic_name, topic_words, (c0_words, c0_scores), (c1_words, c1_scores) = get_topic_words_with_ratio(t, limit=10)\n",
    "    \n",
    "    r = {\n",
    "        'topic': topic_name,\n",
    "        'topic_words': join_and_Capitalize(topic_words[:7]),\n",
    "        'c0_words': join_and_Capitalize(c0_words[:7]),\n",
    "        'c1_words': join_and_Capitalize(c1_words[:7]),\n",
    "    }\n",
    "    \n",
    "    records.append(r)\n",
    "\n",
    "df_profile_words = pd.DataFrame(records, columns=['topic', 'topic_words', 'c0_words', 'c1_words'])\n",
    "df_profile_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_profile_words.to_latex(\"profile_words.tex\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as a CSV file\n",
    "df_profile_words.to_csv(f'analysis/{dataset}_profile_words.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_echo_profile_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
